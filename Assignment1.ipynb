{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub repository\n",
    "Link to repository used to colaborate on the assignment:\n",
    "https://github.com/KarolineKlan/Assignments_ComSocSci2024.git\n",
    "\n",
    "### Contribution statement\n",
    "\n",
    "Team members:\n",
    "\n",
    "- Jacob (s214596)\n",
    "- Kristoffer (s214609)\n",
    "- Karoline (s214638)\n",
    "\n",
    "All members collaborated and contributed to every part of the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "This assignment was formed using Web-scraping tools from the program of the International Conference in Computational Social Science 2023  https://ic2s2-2023.org/program, and acessing data of Authors and Research Articles using the OpenAlex API https://docs.openalex.org/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import ast\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Webscraping\n",
    "In the following task we use web-scraping tools to get the list of participants in the International Conference in Computational Social Science (CSC) 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique speakers:  1472\n",
      "Number of unique keynote speakers:  10\n",
      "Number of unique chairs:  49\n",
      "Number of unique members from optional link1:  333\n",
      "Number of unique teachers from optional link2:  19\n",
      "Total number of unique speakers:  1645\n"
     ]
    }
   ],
   "source": [
    "# define link to scrape, and beautifulsoup object\n",
    "LINK = \"https://ic2s2-2023.org/program\"\n",
    "LINK_OPTIONAL1 = \"https://ic2s2-2023.org/program_committee\"\n",
    "r_OPTIONAL1 = requests.get(LINK_OPTIONAL1)\n",
    "soup_OPTIONAL1 = BeautifulSoup(r_OPTIONAL1.content)\n",
    "LINK_OPTIONAL2 = \"https://ic2s2-2023.org/tutorials\"\n",
    "r_OPTIONAL2 = requests.get(LINK_OPTIONAL2)\n",
    "soup_OPTIONAL2 = BeautifulSoup(r_OPTIONAL2.content)\n",
    "r = requests.get(LINK)\n",
    "soup = BeautifulSoup(r.content)\n",
    "\n",
    "# Find all relevant places in the HTML code where names are stored\n",
    "speaker = soup.findAll(\"ul\", {\"class\" : \"nav_list\"})\n",
    "chair = soup.findAll(\"h2\")\n",
    "table = soup.find(\"table\", {\"class\" : \"tutorials\"})\n",
    "table = table.find_all(\"td\")\n",
    "main = soup_OPTIONAL1.find(\"section\", {\"id\" : \"main\"})\n",
    "names_members = main.findAll(\"li\")\n",
    "names_teachers = soup_OPTIONAL2.findAll(\"div\", {\"class\" : \"col-5 col-12-medium\"})\n",
    "\n",
    "# Loop through the HTML code and extract names\n",
    "keynote_names = [table[k].text.lower().split(\"- \")[1] for k in range(len(table)) if \"Keynote\" in table[k].text]\n",
    "chair_names = [chair[k].text.lower().split(\": \")[2] for k in range(len(chair)) if \"Chair\" in chair[k].text]\n",
    "speaker_names = [speaker[k].find_all(\"i\")[j].text.lower().split(\", \")  for k in range(len(speaker)) for j in range(len(speaker[k].find_all(\"i\")))]\n",
    "speaker_names = sum(speaker_names, [])\n",
    "names_members_lst = [names_members[i].find(\"b\").text.lower() for i in range(len(names_members))]\n",
    "names_teachers = [names_teachers[i].findAll(\"li\")[k].find(\"b\").text.lower() for i in range(len(names_teachers)) for k in range(len(names_teachers[i].findAll(\"li\")))]\n",
    "\n",
    "\n",
    "\n",
    "# Print results for each category\n",
    "print(f\"Number of unique speakers:  {len(set(speaker_names))}\")\n",
    "print(f\"Number of unique keynote speakers:  {len(set(keynote_names))}\")\n",
    "print(f\"Number of unique chairs:  {len(set(chair_names))}\")\n",
    "print(f\"Number of unique members from optional link1:  {len(set(names_members_lst))}\")\n",
    "print(f\"Number of unique teachers from optional link2:  {len(set(names_teachers))}\")\n",
    "\n",
    "# Add all names together to find total unique names\n",
    "total_names = speaker_names + keynote_names + chair_names + names_members_lst + names_teachers\n",
    "df = pd.DataFrame(total_names, columns = [\"Name\"])\n",
    "df[\"Name\"] = df[\"Name\"].str.replace(\".\", \"\")\n",
    "uniq_names = pd.DataFrame(set(df[\"Name\"]), columns=[\"Name\"])\n",
    "#uniq_names = uniq_names.sort_values('Name', ascending=True)\n",
    "print(f\"Total number of unique speakers:  {len((uniq_names))}\")\n",
    "\n",
    "pd.DataFrame(uniq_names).to_csv(\"data/authors_part1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['étienne ollion',\n",
       " 'rubing shen',\n",
       " 'yelena mejova',\n",
       " 'kyriaki kalimeri',\n",
       " 'giovanni da san martino',\n",
       " 'oscar araque',\n",
       " 'michael szell',\n",
       " 'ane rahbek vierø',\n",
       " 'anastassia vybornova',\n",
       " 'mohammed alsobay',\n",
       " 'james houghton',\n",
       " 'james evans',\n",
       " 'bhargav srinivasa desikan',\n",
       " 'august lohse',\n",
       " 'simon p. von der maase',\n",
       " 'sanja šćepanović',\n",
       " 'ingmar weber',\n",
       " 'philipp lorenz-spreen',\n",
       " 'julian jaursch']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "names_teachers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**The process of the web-scraping:** \n",
    "\n",
    "In the process of web-scraping the website and collect the specific names of all the researchers, a thourough investigation of the HTML setup was initiated in order to understand the hierarchical and nested structure of the page. The main structure of the page was after inspection divided into 3 main parts, where different approaches were utilized in order to access the data from different structures:\n",
    "1. collect the names og the key-note speakers from the overview table structure\n",
    "2. collect the names for the chair speakers in the \"h2\" sections\n",
    "3. collect names from the text sections in the \"ul\" sections "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Ready Made vs Custom Made Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Gathering Research Articles using the OpenAlex API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview and Reflection questions: \n",
    "\n",
    "- **Dataset summary.** \n",
    "\n",
    "- **Efficiency in code.** \n",
    "\n",
    "\n",
    "- **Filtering Criteria and Dataset Relevance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: The Network of Computational Social Scientists\n",
    "\n",
    "In this part of the assignment we construct and investigate the Computational Social Scientists Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comsocsci2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
