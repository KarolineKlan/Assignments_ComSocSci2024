{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub repository\n",
    "Link to repository used to colaborate on the assignment:\n",
    "https://github.com/KarolineKlan/Assignments_ComSocSci2024.git\n",
    "\n",
    "### Contribution statement\n",
    "\n",
    "Team members:\n",
    "\n",
    "- Jacob (s214596)\n",
    "- Kristoffer (s214609)\n",
    "- Karoline (s214638)\n",
    "\n",
    "All members collaborated and contributed to every part of the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "This assignment was formed using Web-scraping tools from the program of the International Conference in Computational Social Science 2023  https://ic2s2-2023.org/program, and acessing data of Authors and Research Articles using the OpenAlex API https://docs.openalex.org/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import ast\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Webscraping\n",
    "In the following task we use web-scraping tools to get the list of participants in the International Conference in Computational Social Science (CSC) 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vg/smyn0xpj4txbs4bxknnvc4zw0000gn/T/ipykernel_17743/1729874768.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique speakers:  1472\n",
      "Number of unique keynote speakers:  10\n",
      "Number of unique chairs:  49\n",
      "Total number of unique speakers:  1488\n"
     ]
    }
   ],
   "source": [
    "# define link to scrape, and beautifulsoup object\n",
    "LINK = \"https://ic2s2-2023.org/program\"\n",
    "r = requests.get(LINK)\n",
    "soup = BeautifulSoup(r.content)\n",
    "\n",
    "# Find all relevant places in the HTML code where names are stored\n",
    "speaker = soup.findAll(\"ul\", {\"class\" : \"nav_list\"})\n",
    "chair = soup.findAll(\"h2\")\n",
    "table = soup.find(\"table\", {\"class\" : \"tutorials\"})\n",
    "table = table.find_all(\"td\")\n",
    "\n",
    "# Loop through the HTML code and extract names\n",
    "keynote_names = [table[k].text.lower().split(\"- \")[1] for k in range(len(table)) if \"Keynote\" in table[k].text]\n",
    "chair_names = [chair[k].text.lower().split(\": \")[2] for k in range(len(chair)) if \"Chair\" in chair[k].text]\n",
    "speaker_names = [speaker[k].find_all(\"i\")[j].text.lower().split(\", \")  for k in range(len(speaker)) for j in range(len(speaker[k].find_all(\"i\")))]\n",
    "speaker_names = sum(speaker_names, [])\n",
    "\n",
    "# Print results for each category\n",
    "print(f\"Number of unique speakers:  {len(set(speaker_names))}\")\n",
    "print(f\"Number of unique keynote speakers:  {len(set(keynote_names))}\")\n",
    "print(f\"Number of unique chairs:  {len(set(chair_names))}\")\n",
    "\n",
    "# Add all names together to find total unique names\n",
    "total_names = speaker_names + keynote_names + chair_names\n",
    "uniq_names = set(total_names)\n",
    "print(f\"Total number of unique speakers:  {len(set(total_names))}\")\n",
    "\n",
    "pd.DataFrame(uniq_names).to_csv(\"data/authors_part1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**The process of the web-scraping:** \n",
    "\n",
    "In the process of web-scraping the website and collect the specific names of all the researchers, a thourough investigation of the HTML setup was initiated in order to understand the hierarchical and nested structure of the page. The main structure of the page was after inspection divided into 3 main parts, where different approaches were utilized in order to access the data from different structures:\n",
    "1. collect the names og the key-note speakers from the overview table structure\n",
    "2. collect the names for the chair speakers in the \"h2\" sections\n",
    "3. collect names from the text sections in the \"ul\" sections "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Ready Made vs Custom Made Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Gathering Research Articles using the OpenAlex API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview and Reflection questions: \n",
    "\n",
    "- **Dataset summary.** \n",
    "\n",
    "- **Efficiency in code.** \n",
    "\n",
    "\n",
    "- **Filtering Criteria and Dataset Relevance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: The Network of Computational Social Scientists\n",
    "\n",
    "In this part of the assignment we construct and investigate the Computational Social Scientists Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comsocsci2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
